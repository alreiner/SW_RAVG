---
title: "SW RAVG gamlss with kfold June 2021"
author: "Alicia Reiner"
date: "7/12/2021"
output: 
  html_document: 
    keep_md: yes
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Load Data and Packages

first load field data

then load PI dataset

rescale CBI data so BEZI Gam distribution can be used (needs 0-1)

data management

```{r Southwest RAVG}
SWRAVG_field=read.csv("RAVG_V18_field.csv",header=TRUE, sep=",")
SWRAVG_PI=read.csv("RAVG_V18_PI.csv",header=TRUE, sep=",")
SWRAVG=read.csv("RAVG_V18.csv",header=TRUE, sep=",")

#create a combined field and PI canopy cover which uses an average if both are present.  
SWRAVG$pdCC<-ifelse(SWRAVG$OS=="Y",((SWRAVG$adj.lim.pdFVSVU+SWRAVG$pdTreeCCloss)/2),ifelse(is.na(SWRAVG$pdTreeCCloss)=="TRUE",SWRAVG$adj.lim.pdFVSVU,SWRAVG$pdTreeCCloss))
SWRAVG_field$pdCC<-ifelse(SWRAVG_field$OS=="Y",((SWRAVG_field$adj.lim.pdFVSVU+SWRAVG_field$pdTreeCCloss)/2),ifelse(is.na(SWRAVG_field$pdTreeCCloss)=="TRUE",SWRAVG_field$adj.lim.pdFVSVU,SWRAVG_field$pdTreeCCloss))

#remove outlier
SWRAVG_field<-SWRAVG_field[-which(SWRAVG_field$Plot=="BLUE11"),]
SWRAVG<-SWRAVG[-which(SWRAVG$Plot=="BLUE11"),]

CBI.B<-((1/3)*(SWRAVG_field$CBI-3)+1)
SWRAVG_field<-cbind(CBI.B,SWRAVG_field)

library(gamlss)
library(ggplot2) 
library(caret)
library(GenKern)
#had to install an older version of caret as package was not recognizing confMatrix()

#fix data types up front
SWRAVG_field$BPScode<-as.factor(SWRAVG_field$BPScode)
SWRAVG_PI$BPScode<-as.factor(SWRAVG_PI$BPScode)
SWRAVG$BPScode<-as.factor(SWRAVG$BPScode)


```

### Partition data for k-fold

not creating folds based on stratified random because intend to apply data to new fires

(Trying to do the kfolds without the 'createFolds' function from caret because it was only assigning 12 obs to test sets.)  

```{r SW RAVG create folds}

set.seed(123)

#randomly shuffle data
SWRAVG_field<-SWRAVG_field[sample(nrow(SWRAVG_field)),]

#create folds
folds_f<-cut(seq(1,nrow(SWRAVG_field)),breaks=7,labels=FALSE)

#again for PI dataset
set.seed(123)
SWRAVG_PI<-SWRAVG_PI[sample(nrow(SWRAVG_PI)),]
folds_PI<-cut(seq(1,nrow(SWRAVG_PI)),breaks=7,labels=FALSE)

#again for combined dataset
set.seed(123)
SWRAVG<-SWRAVG[sample(nrow(SWRAVG)),]
folds<-cut(seq(1,nrow(SWRAVG)),breaks=7,labels=FALSE)

```


### SW RAVG stepGAICAll.A CBI

This code chunk uses the stepGAICAll.A() function to test for linear, smoothed, and interaction terms for each mu, sigma, nu, and tau

4/27 - commenting this section out as results are fairly stable and to reduce run time & output

```{r SW RAVG stepGAICAll.A CBI}

#create initial model for stepGAICAll.A

#CBI.0<-gamlss(CBI.B ~ L_EA_rdnbr_with, family= BEINF, data=na.omit(SWRAVG_field))
#CBI.0

#search for best terms to include for each distribution parameter

#in previous run, model below failed
#CBI.1<- stepGAICAll.A(CBI.0, scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f + (L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f)^2 + pb(L_EA_rdnbr_with) + pb(elev) + pb(TCI) + pb(slope) +pb(LEA_preN_f)))
#CBI.1

#restrict sigma
#in previous run model failed
#CBI.2<- stepGAICAll.A(CBI.0, scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f + (L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f)^2 + pb(L_EA_rdnbr_with) + pb(elev) + pb(TCI) + pb(slope) + pb(LEA_preN_f)), sigma.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f))


#restrict nu and sigma
#in previous runs model below failed trying to fit tau
#CBI.3<- stepGAICAll.A(CBI.0, scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f +(L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f)^2 + pb(L_EA_rdnbr_with) + pb(elev) + pb(TCI) + pb(slope) + pb(LEA_preN_f), sigma.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f), nu.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f)))


#restrict sigma nu and tau
# during previous run model below converged without LEA_preN_f, did not converge with it
#CBI.4<- stepGAICAll.A(CBI.0, scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f +(L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f)^2 + pb(L_EA_rdnbr_with) + pb(elev) + pb(TCI) + pb(slope) + pb(LEA_preN_f), sigma.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f), nu.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f), tau.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f)))
#CBI.4


#CBI.5<-stepGAICAll.A(CBI.0, scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope +(L_EA_rdnbr_with + elev + TCI + slope)^2 + pb(L_EA_rdnbr_with) + pb(elev) + pb(TCI) + pb(slope), sigma.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope), nu.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope), tau.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope)))

```


### Create fitted values, accuracies and Kappa

Create predicted values of the response variable for the reserve dataset in order to calculate confusion matrices, accuracies and kappa. 

Gamlss phrases nu and tau as odds.  The code below converts these odds of nu or tau into probabilities of 0 or 1, respectively. The predicted values are computed using the continuous response (mu) as well as the probability of zero or one.   

```{r SW RAVG CBI gamlss accuracies}

#set up blank lists to store results
CBI.M.Ac<-c()
CBI.M.K<-c()
CBI.testMSE<-c()
CBI.AIC<-c()

#create a blank vector to hold ifelse predictions, aka, predictions with asymptotes
CBI.pred.M.if<-999

for(i in 1:7){

  #Segement your data by fold using the which() function 
    testIndexes <- which(folds_f==i,arr.ind=TRUE)
    SWRAVG_field_test <- SWRAVG_field[testIndexes, ]
    SWRAVG_field_train <- SWRAVG_field[-testIndexes, ]

#rephrase results from stepGAICAll.A into the 'CBI.multivar' model below
CBI.multivar<-gamlss(formula=CBI.B~L_EA_rdnbr_with+pb(TCI)+pb(L_EA_rdnbr_with),sigma.formula = ~L_EA_rdnbr_with, nu.formula=~L_EA_rdnbr_with, tau.formula=~L_EA_rdnbr_with,family=BEINF,data=na.omit(SWRAVG_field_train))

# extract new predictions for BEINF gamlss parameters for multivariate model
  CBI.multivar.predAll <- predictAll(CBI.multivar, newdata=SWRAVG_field_test, type="response") 
  mu.CBI.m <- CBI.multivar.predAll$mu
  nu.CBI.m <- CBI.multivar.predAll$nu
  tau.CBI.m <- CBI.multivar.predAll$tau
  p0.CBI.m <- nu.CBI.m / (1+nu.CBI.m+tau.CBI.m) # probability of zeros
  p1.CBI.m <- tau.CBI.m / (1+nu.CBI.m+tau.CBI.m) # probability of ones

#converting the odds of nu or tau into probabilities p0 and p1 
#convert odds to probability by dividing the odds by one plus the odds
#since either nu or tau is >0, but not both, having both nu and tau in the denominator is fine

# calculate predictions based on full gamlss model
yest.CBI.m.gamlss <- (1-p0.CBI.m)*(p1.CBI.m+(1-p1.CBI.m)*mu.CBI.m)


CBI.testMSE.0<-mean((SWRAVG_field_test$CBI.B-yest.CBI.m.gamlss)^2) 
CBI.testMSE<-c(CBI.testMSE,CBI.testMSE.0)
CBI.AIC.0<-AIC(CBI.multivar)
CBI.AIC<-c(CBI.AIC,CBI.AIC.0)

#create confusion matrix for multivariate gamlss predictions

#first categorize the reserve CBI data (the CBI.B variable on 0-1 scale)
SWRAVG_field_test$CBI.cat=cut(SWRAVG_field_test$CBI.B,
                breaks=c(-Inf,0.0329,0.415,0.749,Inf),
                labels=c("0-<0.1","0.1-<1.25","1.25-<2.25","2.25-3"))

#then categorize the predicted data  
yest.CBI.m.cat=cut(yest.CBI.m.gamlss,
breaks=c(-Inf,0.0329,0.415,0.749,Inf),
                labels=c("0-<0.1","0.1-<1.25","1.25-<2.25","2.25-3"))

#Create Confusion Matrix
CBI.M.conf<-confusionMatrix(yest.CBI.m.cat, SWRAVG_field_test$CBI.cat,  dnn = c("Prediction", "Reference"))
print(CBI.M.conf)

#access accuracy and Kappa
CBI.conf.M.ac<-CBI.M.conf$overall["Accuracy"]
CBI.conf.M.K<-CBI.M.conf$overall["Kappa"]

#add accuracy and Kappa to lists
CBI.M.Ac<-c(CBI.M.Ac,CBI.conf.M.ac)
CBI.M.K<-c(CBI.M.K,CBI.conf.M.K)
}

#average the results across folds
mean(CBI.M.Ac)
sd(CBI.M.Ac)/sqrt(length(CBI.M.Ac))
mean(CBI.M.K)
sd(CBI.M.K)/sqrt(length(CBI.M.K))
mean(CBI.testMSE)
mean(CBI.AIC)


#also run the simplest model for comparison

#set up blank lists to store results
CBI.S.Ac<-c()
CBI.S.K<-c()
CBI.testMSE.S<-c()
CBI.AIC.S<-c()

#create a blank vector to hold ifelse predictions, aka, predictions with asymptotes
CBI.pred.S.if<-999

for(i in 1:7){

  #Segement your data by fold using the which() function 
    testIndexes <- which(folds_f==i,arr.ind=TRUE)
    SWRAVG_field_test <- SWRAVG_field[testIndexes, ]
    SWRAVG_field_train <- SWRAVG_field[-testIndexes, ]

CBI.simple<-gamlss(formula=CBI.B~L_EA_rdnbr_with, nu.formula=~L_EA_rdnbr_with, tau.formula=~L_EA_rdnbr_with,family=BEINF,data=na.omit(SWRAVG_field_train))

# extract new predictions for BEINF gamlss parameters for simple model
  CBI.simple.predAll <- predictAll(CBI.simple, newdata=SWRAVG_field_test, type="response") 
  mu.CBI.s <- CBI.simple.predAll$mu
  nu.CBI.s <- CBI.simple.predAll$nu
  tau.CBI.s <- CBI.simple.predAll$tau
  p0.CBI.s <- nu.CBI.s / (1+nu.CBI.s+tau.CBI.s) # probability of zeros
  p1.CBI.s <- tau.CBI.s / (1+nu.CBI.s+tau.CBI.s) # probability of ones

# calculate expected value for new predictions
yest.CBI.s.gamlss <- (1-p0.CBI.s)*(p1.CBI.s+(1-p1.CBI.s)*mu.CBI.s)

#first categorize the reserve CBI data (the CBI.B variable on 0-1 scale)
SWRAVG_field_test$CBI.cat=cut(SWRAVG_field_test$CBI.B,
       breaks=c(-Inf,0.0329,0.415,0.749,Inf),
                labels=c("0-<0.1","0.1-<1.25","1.25-<2.25","2.25-3"))

#then categorize the predicted data  
yest.CBI.s.cat=cut(yest.CBI.s.gamlss,
breaks=c(-Inf,0.0329,0.415,0.749,Inf),
                labels=c("0-<0.1","0.1-<1.25","1.25-<2.25","2.25-3"))


CBI.testMSE.S.0<-mean((SWRAVG_field_test$CBI.B-yest.CBI.s.gamlss)^2) 
CBI.testMSE.S<-c(CBI.testMSE.S,CBI.testMSE.S.0)
CBI.AIC.S.0<-AIC(CBI.simple)
CBI.AIC.S<-c(CBI.AIC.S,CBI.AIC.S.0)

#Create Confusion Matrix
CBI.S.conf<-confusionMatrix(yest.CBI.s.cat, SWRAVG_field_test$CBI.cat,  dnn = c("Prediction", "Reference"))
print(CBI.S.conf)

#access accuracy and Kappa
CBI.conf.S.ac<-CBI.S.conf$overall["Accuracy"]
CBI.conf.S.K<-CBI.S.conf$overall["Kappa"]

#add accuracy and Kappa to lists
CBI.S.Ac<-c(CBI.S.Ac,CBI.conf.S.ac)
CBI.S.K<-c(CBI.S.K,CBI.conf.S.K)

plot(yest.CBI.s.gamlss,SWRAVG_field_test$CBI.B, xlab="yest for simple gamlss on model set", ylab="actual", main = "predicted vs actual values of CBI for simple gamlss with limits")

}

#average the results across folds
mean(CBI.S.Ac)
sd(CBI.S.Ac)/sqrt(length(CBI.S.Ac))
mean(CBI.S.K)
sd(CBI.S.K)/sqrt(length(CBI.S.K))
mean(CBI.testMSE.S)
mean(CBI.AIC.S)



```


### SW RAVG stepGAICAll.A BA

This code chunk uses the stepGAICAll.A() function to test for linear, smoothed, and interaction terms for each mu, sigma, nu, and tau

4/27 - commenting this section out as results are fairly stable and to reduce run time & output

```{r SW RAVG stepGAICAll.A BA}

#create initial model for stepGAICAll.A

#BA.0<-gamlss(pdBA ~ L_EA_rdnbr_with, family= BEINF, data=na.omit(SWRAVG_field))
#BA.0

#search for best terms to include for each distribution parameter

#model below is commented out, it failed trying to fit sigma
#BA.1<- stepGAICAll.A(BA.0, scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f +(L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f)^2 + cs(L_EA_rdnbr_with) + cs(elev) + cs(TCI) + cs(slope) + cs(LEA_preN_f)))


#model below is commented out, it failed trying to fit nu
#BA.2<- stepGAICAll.A(BA.0, scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f +(L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f)^2 + cs(L_EA_rdnbr_with) + cs(elev) + cs(TCI) + cs(slope) + cs(LEA_preN_f)), sigma.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f))


#resulting model commented out, it failed 
#BA.3<- stepGAICAll.A(BA.0, scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f +(L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f)^2 + cs(L_EA_rdnbr_with) + cs(elev) + cs(TCI) + cs(slope) + cs(LEA_preN_f)), sigma.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f), nu.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f))

#model below failed trying to fit sigma
#BA.4<- stepGAICAll.A(BA.0, scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f + (L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f)^2 + cs(L_EA_rdnbr_with) + cs(elev) + cs(TCI) + cs(slope) + cs(LEA_preN_f)), sigma.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f), nu.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f), tau.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f))
#BA.4

#remove LEA_preN_f from sigma
#BA.5<- stepGAICAll.A(BA.0, scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f +(L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f)^2 + cs(L_EA_rdnbr_with) + cs(elev) + cs(TCI) + cs(slope) + cs(LEA_preN_f)), sigma.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope))

#simplify all terms
#BA.7<- stepGAICAll.A(BA.0, scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f), sigma.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f))

```


### Create fitted values, accuracies and Kappa for BA

Create predicted values of the response variable for the reserve dataset in order to calcualte confusion matrices, accuracies and kappa. 

Gamlss phrases nu and tau as odds.  The code below converts these odds of nu or tau into probabilities of 0 or 1, respectively. The predicted values are computed using the continuous response (mu) as well as the probability of zero or one.   

```{r SW RAVG BA gamlss accuracies}

#set up blank lists to store results
BA.M.Ac<-c()
BA.M.K<-c()
BA.testMSE<-c()
BA.AIC<-c()

#create a blank vector to hold ifelse predictions, aka, predictions with asymptotes
BA.pred.M.if<-999

for(i in 1:7){

  #Segement your data by fold using the which() function 
    testIndexes <- which(folds_f==i,arr.ind=TRUE)
    SWRAVG_field_test <- SWRAVG_field[testIndexes, ]
    SWRAVG_field_train <- SWRAVG_field[-testIndexes, ]


#rephrase results from stepGAICAll.A into the 'BA.multivar' model below
BA.multivar<-gamlss(formula=pdBA~L_EA_rdnbr_with, sigma.formula=~L_EA_rdnbr_with+slope,nu.formula=~L_EA_rdnbr_with+LEA_preN_f, tau.formula=~L_EA_rdnbr_with+slope,family=BEINF,data=na.omit(SWRAVG_field_train))

# extract new predictions for BEINF gamlss parameters for multivariate model
  BA.multivar.predAll <- predictAll(BA.multivar, newdata=SWRAVG_field_test, type="response") 
  mu.BA.m <- BA.multivar.predAll$mu
  nu.BA.m <- BA.multivar.predAll$nu
  tau.BA.m <- BA.multivar.predAll$tau
  p0.BA.m <- nu.BA.m / (1+nu.BA.m+tau.BA.m) # probability of zeros
  p1.BA.m <- tau.BA.m / (1+nu.BA.m+tau.BA.m) # probability of ones

# calculate gamlss predictions for multivariate model on reserve set
yest.BA.m.gamlss <- (1-p0.BA.m)*(p1.BA.m+(1-p1.BA.m)*mu.BA.m)


BA.testMSE.0<-mean((SWRAVG_field_test$pdBA-yest.BA.m.gamlss)^2) 
BA.testMSE<-c(BA.testMSE,BA.testMSE.0)
BA.AIC.0<-AIC(BA.multivar)
BA.AIC<-c(BA.AIC,BA.AIC.0)

#first categorize the reserve pdBA data 
SWRAVG_field_test$pdBA.cat=cut(SWRAVG_field_test$pdBA,
                           breaks=c(-Inf,0.0999,0.24999,0.4999,0.74999,0.8999, Inf),
                labels=c("0-<10%","10-<25%","25-<50%","50-<75%","75-<90%","90-100%"))

#then categorize the predicted data  
yest.BA.m.cat=cut(yest.BA.m.gamlss,
                  breaks=c(-Inf,0.0999,0.24999,0.4999,0.74999,0.8999, Inf),
                labels=c("0-<10%","10-<25%","25-<50%","50-<75%","75-<90%","90-100%"))

#Create Confusion Matrix
BA.M.conf<-confusionMatrix(yest.BA.m.cat, SWRAVG_field_test$pdBA.cat,  dnn = c("Prediction", "Reference"))
print(BA.M.conf)

#access accuracy and Kappa
BA.conf.M.ac<-BA.M.conf$overall["Accuracy"]
BA.conf.M.K<-BA.M.conf$overall["Kappa"]

#add accuracy and Kappa to lists
BA.M.Ac<-c(BA.M.Ac,BA.conf.M.ac)
BA.M.K<-c(BA.M.K,BA.conf.M.K)
}

#average the results across folds
mean(BA.M.Ac)
sd(BA.M.Ac)/sqrt(length(BA.M.Ac))
mean(BA.M.K)
sd(BA.M.K)/sqrt(length(BA.M.K))
mean(BA.testMSE)
mean(BA.AIC)




#also run the simplest model for comparison

#set up blank lists to store results
BA.S.Ac<-c()
BA.S.K<-c()
BA.testMSE.S<-c()
BA.AIC.S<-c()

#create a blank vector to hold ifelse predictions, aka, predictions with asymptotes
BA.pred.S.if<-999

for(i in 1:7){

  #Segement your data by fold using the which() function 
    testIndexes <- which(folds_f==i,arr.ind=TRUE)
    SWRAVG_field_test <- SWRAVG_field[testIndexes, ]
    SWRAVG_field_train <- SWRAVG_field[-testIndexes, ]

BA.simple<-gamlss(formula=pdBA~L_EA_rdnbr_with, sigma.formula=~L_EA_rdnbr_with,nu.formula=~L_EA_rdnbr_with, tau.formula=~L_EA_rdnbr_with,family=BEINF,data=na.omit(SWRAVG_field_train))

# extract new predictions for BEINF gamlss parameters for simple model
  BA.simple.predAll <- predictAll(BA.simple, newdata=SWRAVG_field_test, type="response") 
  mu.BA.s <- BA.simple.predAll$mu
  nu.BA.s <- BA.simple.predAll$nu
  tau.BA.s <- BA.simple.predAll$tau
  p0.BA.s <- nu.BA.s / (1+nu.BA.s+tau.BA.s) # probability of zeros
  p1.BA.s <- tau.BA.s / (1+nu.BA.s+tau.BA.s) # probability of ones

# calculate expected value for new predictions for simple model
yest.BA.s.gamlss <- (1-p0.BA.s)*(p1.BA.s+(1-p1.BA.s)*mu.BA.s)

BA.testMSE.S.0<-mean((SWRAVG_field_test$pdBA-yest.BA.s.gamlss)^2) 
BA.testMSE.S<-c(BA.testMSE.S,BA.testMSE.S.0)
BA.AIC.S.0<-AIC(BA.simple)
BA.AIC.S<-c(BA.AIC.S,BA.AIC.S.0)

#first categorize the reserve pdBA data 
SWRAVG_field_test$pdBA.cat=cut(SWRAVG_field_test$pdBA,
                              breaks=c(-Inf,0.0999,0.24999,0.4999,0.74999,0.8999, Inf),
                labels=c("0-<10%","10-<25%","25-<50%","50-<75%","75-<90%","90-100%"))

#then categorize the predicted data  
yest.BA.s.cat=cut(yest.BA.s.gamlss,
                breaks=c(-Inf,0.0999,0.24999,0.4999,0.74999,0.8999, Inf),
                labels=c("0-<10%","10-<25%","25-<50%","50-<75%","75-<90%","90-100%"))

#Create Confusion Matrix
BA.S.conf<-confusionMatrix(yest.BA.s.cat, SWRAVG_field_test$pdBA.cat,  dnn = c("Prediction", "Reference"))
print(BA.S.conf)

#access accuracy and Kappa
BA.conf.S.ac<-BA.S.conf$overall["Accuracy"]
BA.conf.S.K<-BA.S.conf$overall["Kappa"]

#add accuracy and Kappa to lists
BA.S.Ac<-c(BA.S.Ac,BA.conf.S.ac)
BA.S.K<-c(BA.S.K,BA.conf.S.K)
}

#average the results across folds
mean(BA.S.Ac)
sd(BA.S.Ac)/sqrt(length(BA.S.Ac))
mean(BA.S.K)
sd(BA.S.K)/sqrt(length(BA.S.K))
mean(BA.testMSE.S)
mean(BA.AIC.S)


```


### SW RAVG stepGAICAll.A pdFVSVU

This code chunk uses the stepGAICAll.A() function to test for linear, smoothed, and interaction terms for each mu, sigma, nu, and tau

4/27 - commenting this section out as results are fairly stable and to reduce run time & output

```{r SW RAVG stepGAICAll.A pdFVSVU}

#create initial model for stepGAICAll.A

#pdFVSVU.0<-gamlss(pdFVSVU ~ L_EA_rdnbr_with, family= BEINF, data=na.omit(SWRAVG_field))
#pdFVSVU.0

#search for best terms to include for each distribution parameter

#model below is commented out, it did not converge
#pdFVSVU.1<- stepGAICAll.A(pdFVSVU.0, scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f + (L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f)^2 + cs(L_EA_rdnbr_with) + cs(elev) + cs(TCI) + cs(slope) + cs(LEA_preN_f)))


#pdFVSVU.2<- stepGAICAll.A(pdFVSVU.0, scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f + (L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f)^2 + cs(L_EA_rdnbr_with) + cs(elev) + cs(TCI) + cs(slope) + cs(LEA_preN_f)), sigma.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f))


#pdFVSVU.3<- stepGAICAll.A(pdFVSVU.0, scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f + (L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f)^2 + cs(L_EA_rdnbr_with) + cs(elev) + cs(TCI) + cs(slope) + cs(LEA_preN_f)), sigma.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f), nu.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f))
#pdFVSVU.3


#pdFVSVU.4<- stepGAICAll.A(pdFVSVU.0, scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f + (L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f)^2 + cs(L_EA_rdnbr_with) + cs(elev) + cs(TCI) + cs(slope) + cs(LEA_preN_f)), sigma.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f), nu.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f),tau.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f))
#pdFVSVU.4

```


### Create fitted values, accuracies and Kappa for pdFVSVU

Create predicted values of the response variable for the reserve dataset in order to calcualte confusion matrices, accuracies and kappa. 

Gamlss phrases nu and tau as odds.  The code below converts these odds of nu or tau into probabilities of 0 or 1, respectively. The predicted values are computed using the continuous response (mu) as well as the probability of zero or one.   

```{r SW RAVG pdFVSVU gamlss accuracies}

#set up blank lists to store results
pdFVSVU.M.Ac<-c()
pdFVSVU.M.K<-c()
pdFVSVU.testMSE<-c()
pdFVSVU.AIC<-c()

#create a blank vector to hold ifelse predictions, aka, predictions with asymptotes
pdFVSVU.pred.M.if<-999

for(i in 1:7){

  #Segement your data by fold using the which() function 
    testIndexes <- which(folds_f==i,arr.ind=TRUE)
    SWRAVG_field_test <- SWRAVG_field[testIndexes, ]
    SWRAVG_field_train <- SWRAVG_field[-testIndexes, ]

#rephrase results from stepGAICAll.A into the 'pdFVSVU.multivar' model below
pdFVSVU.multivar<-gamlss(formula=pdFVSVU~L_EA_rdnbr_with + cs(elev),  
    sigma.formula = ~L_EA_rdnbr_with, nu.formula = ~L_EA_rdnbr_with +  
        TCI, tau.formula = ~L_EA_rdnbr_with + elev +  
        slope + LEA_preN_f + TCI,family=BEINF,data=na.omit(SWRAVG_field_train))

# extract new predictions for BEINF gamlss parameters for multivariate model
  pdFVSVU.multivar.predAll <- predictAll(pdFVSVU.multivar, newdata=SWRAVG_field_test, type="response") 
  mu.pdFVSVU.m <- pdFVSVU.multivar.predAll$mu
  nu.pdFVSVU.m <- pdFVSVU.multivar.predAll$nu
  tau.pdFVSVU.m <- pdFVSVU.multivar.predAll$tau
  p0.pdFVSVU.m <- nu.pdFVSVU.m / (1+nu.pdFVSVU.m+tau.pdFVSVU.m) # probability of zeros
  p1.pdFVSVU.m <- tau.pdFVSVU.m / (1+nu.pdFVSVU.m+tau.pdFVSVU.m) # probability of ones

# calculate expected value for new predictions for multivariate model
yest.pdFVSVU.m.gamlss <- (1-p0.pdFVSVU.m)*(p1.pdFVSVU.m+(1-p1.pdFVSVU.m)*mu.pdFVSVU.m)

pdFVSVU.testMSE.0<-mean((SWRAVG_field_test$pdFVSVU-yest.pdFVSVU.m.gamlss)^2) 
pdFVSVU.testMSE<-c(pdFVSVU.testMSE,pdFVSVU.testMSE.0)
pdFVSVU.AIC.0<-AIC(pdFVSVU.multivar)
pdFVSVU.AIC<-c(pdFVSVU.AIC,pdFVSVU.AIC.0)

#first categorize the reserve pdBA data 
SWRAVG_field_test$pdFVSVU.cat=cut(SWRAVG_field_test$pdFVSVU,
                            breaks=c(-Inf,0.0999,0.24999,0.4999,0.74999,0.8999, Inf),
                labels=c("0-<10%","10-<25%","25-<50%","50-<75%","75-<90%","90-100%"))

#then categorize the predicted data  
yest.pdFVSVU.m.cat=cut(yest.pdFVSVU.m.gamlss,
                            breaks=c(-Inf,0.0999,0.24999,0.4999,0.74999,0.8999, Inf),
                labels=c("0-<10%","10-<25%","25-<50%","50-<75%","75-<90%","90-100%"))

#Create Confusion Matrix
pdFVSVU.M.conf<-confusionMatrix(yest.pdFVSVU.m.cat, SWRAVG_field_test$pdFVSVU.cat,  dnn = c("Prediction", "Reference"))
print(pdFVSVU.M.conf)

#access accuracy and Kappa
pdFVSVU.conf.M.ac<-pdFVSVU.M.conf$overall["Accuracy"]
pdFVSVU.conf.M.K<-pdFVSVU.M.conf$overall["Kappa"]

#add accuracy and Kappa to lists
pdFVSVU.M.Ac<-c(pdFVSVU.M.Ac,pdFVSVU.conf.M.ac)
pdFVSVU.M.K<-c(pdFVSVU.M.K,pdFVSVU.conf.M.K)
}

#average the results across folds
mean(pdFVSVU.M.Ac)
sd(pdFVSVU.M.Ac)/sqrt(length(pdFVSVU.M.Ac))
mean(pdFVSVU.M.K)
sd(pdFVSVU.M.K)/sqrt(length(pdFVSVU.M.K))
mean(pdFVSVU.testMSE)
mean(pdFVSVU.AIC)


#also run the simplest model for comparison

#set up blank lists to store results
pdFVSVU.S.Ac<-c()
pdFVSVU.S.K<-c()
pdFVSVU.testMSE.S<-c()
pdFVSVU.AIC.S<-c()

#create a blank vector to hold ifelse predictions, aka, predictions with asymptotes
pdFVSVU.pred.S.if<-999

for(i in 1:7){

  #Segement your data by fold using the which() function 
    testIndexes <- which(folds_f==i,arr.ind=TRUE)
    SWRAVG_field_test <- SWRAVG_field[testIndexes, ]
    SWRAVG_field_train <- SWRAVG_field[-testIndexes, ]

pdFVSVU.simple<-gamlss(formula=pdFVSVU~L_EA_rdnbr_with, sigma.formula=~L_EA_rdnbr_with,nu.formula=~L_EA_rdnbr_with, tau.formula=~L_EA_rdnbr_with,family=BEINF,data=na.omit(SWRAVG_field_train))

# extract new predictions for BEINF gamlss parameters for simple model
pdFVSVU.simple.predAll <- predictAll(pdFVSVU.simple, newdata=SWRAVG_field_test, type="response") 
  mu.pdFVSVU.s <- pdFVSVU.simple.predAll$mu
  nu.pdFVSVU.s <- pdFVSVU.simple.predAll$nu
  tau.pdFVSVU.s <- pdFVSVU.simple.predAll$tau
  p0.pdFVSVU.s <- nu.pdFVSVU.s / (1+nu.pdFVSVU.s+tau.pdFVSVU.s) # propdabbility of zeros
  p1.pdFVSVU.s <- tau.pdFVSVU.s / (1+nu.pdFVSVU.s+tau.pdFVSVU.s) # probability of ones

# calculate expected value for new predictions for simple model
yest.pdFVSVU.s.gamlss <- (1-p0.pdFVSVU.s)*(p1.pdFVSVU.s+(1-p1.pdFVSVU.s)*mu.pdFVSVU.s)

pdFVSVU.testMSE.S.0<-mean((SWRAVG_field_test$pdFVSVU-yest.pdFVSVU.s.gamlss)^2) 
pdFVSVU.testMSE.S<-c(pdFVSVU.testMSE.S,pdFVSVU.testMSE.S.0)
pdFVSVU.AIC.S.0<-AIC(pdFVSVU.simple)
pdFVSVU.AIC.S<-c(pdFVSVU.AIC.S,pdFVSVU.AIC.S.0)


#first categorize the reserve pdPDFVSVU data 
SWRAVG_field_test$pdFVSVU.cat=cut(SWRAVG_field_test$pdFVSVU,
                     breaks=c(-Inf,0.0999,0.24999,0.4999,0.74999,0.8999, Inf),
                labels=c("0-<10%","10-<25%","25-<50%","50-<75%","75-<90%","90-100%"))

#then categorize the predicted data  
yest.pdFVSVU.s.cat=cut(yest.pdFVSVU.s.gamlss,
                             breaks=c(-Inf,0.0999,0.24999,0.4999,0.74999,0.8999, Inf),
                labels=c("0-<10%","10-<25%","25-<50%","50-<75%","75-<90%","90-100%"))

#Create Confusion Matrix
pdFVSVU.S.conf<-confusionMatrix(yest.pdFVSVU.s.cat, SWRAVG_field_test$pdFVSVU.cat,  dnn = c("Prediction", "Reference"))
print(pdFVSVU.S.conf)

#access accuracy and Kappa
pdFVSVU.conf.S.ac<-pdFVSVU.S.conf$overall["Accuracy"]
pdFVSVU.conf.S.K<-pdFVSVU.S.conf$overall["Kappa"]

#add accuracy and Kappa to lists
pdFVSVU.S.Ac<-c(pdFVSVU.S.Ac,pdFVSVU.conf.S.ac)
pdFVSVU.S.K<-c(pdFVSVU.S.K,pdFVSVU.conf.S.K)
}

#average the results across folds
mean(pdFVSVU.S.Ac)
sd(pdFVSVU.S.Ac)/sqrt(length(pdFVSVU.S.Ac))
mean(pdFVSVU.S.K)
sd(pdFVSVU.S.K)/sqrt(length(pdFVSVU.S.K))
mean(pdFVSVU.testMSE.S)
mean(pdFVSVU.AIC.S)


```




### SW RAVG stepGAICAll.A adj.lim.pdFVSVU

This code chunk uses the stepGAICAll.A() function to test for linear, smoothed, and interaction terms for each mu, sigma, nu, and tau

4/27 - commenting this section out as results are fairly stable and to reduce run time & output

```{r SW RAVG stepGAICAll.A adj.lim.pdFVSVU}

#create initial model for stepGAICAll.A

#adj.lim.pdFVSVU.0<-gamlss(adj.lim.pdFVSVU ~ L_EA_rdnbr_with, family= BEINF, data=na.omit(SWRAVG_field))
#adj.lim.adj.lim.pdFVSVU.0

#search for best terms to include for each distribution parameter

#model below is commented out, it failed trying to fit sigma
#adj.lim.pdFVSVU.1<- stepGAICAll.A(adj.lim.pdFVSVU.0, scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f + (L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f)^2 + cs(L_EA_rdnbr_with) + cs(elev) + cs(TCI) + cs(slope) + cs(LEA_preN_f)))

#model below is commented out, it failed trying to fit sigma - but yeilds same model as 3 and 4, and looks like best model based on AIC
#adj.lim.pdFVSVU.2<- stepGAICAll.A(adj.lim.pdFVSVU.0, scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f + (L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f)^2 + cs(L_EA_rdnbr_with) + cs(elev) + cs(TCI) + cs(slope) + cs(LEA_preN_f)), sigma.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f))

#model below is commented out, it failed trying to fit sigma
#adj.lim.pdFVSVU.3<- stepGAICAll.A(adj.lim.pdFVSVU.0, scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f + (L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f)^2 + cs(L_EA_rdnbr_with) + cs(elev) + cs(TCI) + cs(slope) + cs(LEA_preN_f)), sigma.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f), nu.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f))
#adj.lim.pdFVSVU.3

#model below is commented out, it failed trying to fit sigma
#adj.lim.pdFVSVU.4<- stepGAICAll.A(adj.lim.pdFVSVU.0, scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f + (L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f)^2 + cs(L_EA_rdnbr_with) + cs(elev) + cs(TCI) + cs(slope) + cs(LEA_preN_f)), sigma.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f), nu.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f),tau.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f))
#adj.lim.pdFVSVU.4

#simplify - but still fails to fit sigma
#adj.lim.pdFVSVU.5<- stepGAICAll.A(adj.lim.pdFVSVU.0, scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f + cs(L_EA_rdnbr_with) + cs(elev) + cs(TCI) + cs(slope) + cs(LEA_preN_f)), sigma.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f), nu.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f),tau.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f))

#simplify - still fails
#adj.lim.pdFVSVU.6<- stepGAICAll.A(adj.lim.pdFVSVU.0, scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f , sigma.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f), nu.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f),tau.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f)))

#still fails
#adj.lim.pdFVSVU.7<- stepGAICAll.A(adj.lim.pdFVSVU.0, scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f , sigma.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope), nu.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope),tau.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope )))

#adj.lim.pdFVSVU.8<- stepGAICAll.A(adj.lim.pdFVSVU.0, scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f , sigma.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with), nu.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope),tau.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope )))

#adj.lim.pdFVSVU.9<- stepGAICAll.A(adj.lim.pdFVSVU.0, scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f , sigma.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with), nu.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with),tau.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with)))

```


### Create fitted values, accuracies and Kappa for adj.lim.pdFVSVU

Create predicted values of the response variable for the reserve dataset in order to calcualte confusion matrices, accuracies and kappa. 

Gamlss phrases nu and tau as odds.  The code below converts these odds of nu or tau into probabilities of 0 or 1, respectively. The predicted values are computed using the continuous response (mu) as well as the probability of zero or one.   

```{r SW RAVG adj.lim.pdFVSVU gamlss accuracies}

#set up blank lists to store results
adj.lim.pdFVSVU.M.Ac<-c()
adj.lim.pdFVSVU.M.K<-c()
adj.lim.pdFVSVU.testMSE<-c()
adj.lim.pdFVSVU.AIC<-c()

#create a blank vector to hold ifelse predictions, aka, predictions with asymptotes
adj.lim.pdFVSVU.pred.M.if<-999

for(i in 1:7){

  #Segement your data by fold using the which() function 
    testIndexes <- which(folds_f==i,arr.ind=TRUE)
    SWRAVG_field_test <- SWRAVG_field[testIndexes, ]
    SWRAVG_field_train <- SWRAVG_field[-testIndexes, ]

#rephrase results from stepGAICAll.A into the 'adj.lim.pdFVSVU.multivar' model below
adj.lim.pdFVSVU.multivar<-gamlss(formula=adj.lim.pdFVSVU~L_EA_rdnbr_with, sigma.formula=~L_EA_rdnbr_with+TCI,nu.formula=~L_EA_rdnbr_with+elev+LEA_preN_f, tau.formula=~L_EA_rdnbr_with+slope,family=BEINF,data=na.omit(SWRAVG_field_train))

# extract new predictions for BEINF gamlss parameters for multivariate model
  adj.lim.pdFVSVU.multivar.predAll <- predictAll(adj.lim.pdFVSVU.multivar, newdata=SWRAVG_field_test, type="response") 
  mu.adj.lim.pdFVSVU.m <- adj.lim.pdFVSVU.multivar.predAll$mu
  nu.adj.lim.pdFVSVU.m <- adj.lim.pdFVSVU.multivar.predAll$nu
  tau.adj.lim.pdFVSVU.m <- adj.lim.pdFVSVU.multivar.predAll$tau
  p0.adj.lim.pdFVSVU.m <- nu.adj.lim.pdFVSVU.m / (1+nu.adj.lim.pdFVSVU.m+tau.adj.lim.pdFVSVU.m) # probability of zeros
  p1.adj.lim.pdFVSVU.m <- tau.adj.lim.pdFVSVU.m / (1+nu.adj.lim.pdFVSVU.m+tau.adj.lim.pdFVSVU.m) # probability of ones

# calculate expected value for new predictions for multivariate model
yest.adj.lim.pdFVSVU.m.gamlss <- (1-p0.adj.lim.pdFVSVU.m)*(p1.adj.lim.pdFVSVU.m+(1-p1.adj.lim.pdFVSVU.m)*mu.adj.lim.pdFVSVU.m)

adj.lim.pdFVSVU.testMSE.0<-mean((SWRAVG_field_test$adj.lim.pdFVSVU-yest.adj.lim.pdFVSVU.m.gamlss)^2) 
adj.lim.pdFVSVU.testMSE<-c(adj.lim.pdFVSVU.testMSE,adj.lim.pdFVSVU.testMSE.0)
adj.lim.pdFVSVU.AIC.0<-AIC(adj.lim.pdFVSVU.multivar)
adj.lim.pdFVSVU.AIC<-c(adj.lim.pdFVSVU.AIC,adj.lim.pdFVSVU.AIC.0)

#first categorize the reserve pdBA data 
SWRAVG_field_test$adj.lim.pdFVSVU.cat=cut(SWRAVG_field_test$adj.lim.pdFVSVU,
                                 breaks=c(-Inf,0.0999,0.24999,0.4999,0.74999,0.8999, Inf),
                labels=c("0-<10%","10-<25%","25-<50%","50-<75%","75-<90%","90-100%"))

#then categorize the predicted data  
yest.adj.lim.pdFVSVU.m.cat=cut(yest.adj.lim.pdFVSVU.m.gamlss,
                                      breaks=c(-Inf,0.0999,0.24999,0.4999,0.74999,0.8999, Inf),
                labels=c("0-<10%","10-<25%","25-<50%","50-<75%","75-<90%","90-100%"))

#Create Confusion Matrix
adj.lim.pdFVSVU.M.conf<-confusionMatrix(yest.adj.lim.pdFVSVU.m.cat, SWRAVG_field_test$adj.lim.pdFVSVU.cat,  dnn = c("Prediction", "Reference"))
print(adj.lim.pdFVSVU.M.conf)

#access accuracy and Kappa
adj.lim.pdFVSVU.conf.M.ac<-adj.lim.pdFVSVU.M.conf$overall["Accuracy"]
adj.lim.pdFVSVU.conf.M.K<-adj.lim.pdFVSVU.M.conf$overall["Kappa"]

#add accuracy and Kappa to lists
adj.lim.pdFVSVU.M.Ac<-c(adj.lim.pdFVSVU.M.Ac,adj.lim.pdFVSVU.conf.M.ac)
adj.lim.pdFVSVU.M.K<-c(adj.lim.pdFVSVU.M.K,adj.lim.pdFVSVU.conf.M.K)
}

#average the results across folds
mean(adj.lim.pdFVSVU.M.Ac)
sd(adj.lim.pdFVSVU.M.Ac)/sqrt(length(adj.lim.pdFVSVU.M.Ac))
mean(adj.lim.pdFVSVU.M.K)
sd(adj.lim.pdFVSVU.M.K)/sqrt(length(adj.lim.pdFVSVU.M.K))
mean(adj.lim.pdFVSVU.testMSE)
mean(adj.lim.pdFVSVU.AIC)



#also run the simplest model for comparison

#set up blank lists to store results
adj.lim.pdFVSVU.S.Ac<-c()
adj.lim.pdFVSVU.S.K<-c()
adj.lim.pdFVSVU.testMSE.S<-c()
adj.lim.pdFVSVU.AIC.S<-c()

#create a blank vector to hold ifelse predictions, aka, predictions with asymptotes
adj.lim.pdFVSVU.pred.S.if<-999

for(i in 1:7){

  #Segement your data by fold using the which() function 
    testIndexes <- which(folds_f==i,arr.ind=TRUE)
    SWRAVG_field_test <- SWRAVG_field[testIndexes, ]
    SWRAVG_field_train <- SWRAVG_field[-testIndexes, ]

adj.lim.pdFVSVU.simple<-gamlss(formula=adj.lim.pdFVSVU~L_EA_rdnbr_with, sigma.formula=~L_EA_rdnbr_with,nu.formula=~L_EA_rdnbr_with, tau.formula=~L_EA_rdnbr_with,family=BEINF,data=na.omit(SWRAVG_field_train))

# extract new predictions for BEINF gamlss parameters for simple model
adj.lim.pdFVSVU.simple.predAll <- predictAll(adj.lim.pdFVSVU.simple, newdata=SWRAVG_field_test, type="response") 
  mu.adj.lim.pdFVSVU.s <- adj.lim.pdFVSVU.simple.predAll$mu
  nu.adj.lim.pdFVSVU.s <- adj.lim.pdFVSVU.simple.predAll$nu
  tau.adj.lim.pdFVSVU.s <- adj.lim.pdFVSVU.simple.predAll$tau
  p0.adj.lim.pdFVSVU.s <- nu.adj.lim.pdFVSVU.s / (1+nu.adj.lim.pdFVSVU.s+tau.adj.lim.pdFVSVU.s) # propdabbility of zeros
  p1.adj.lim.pdFVSVU.s <- tau.adj.lim.pdFVSVU.s / (1+nu.adj.lim.pdFVSVU.s+tau.adj.lim.pdFVSVU.s) # probability of ones

# calculate expected value for new predictions for simple model
yest.adj.lim.pdFVSVU.s.gamlss <- (1-p0.adj.lim.pdFVSVU.s)*(p1.adj.lim.pdFVSVU.s+(1-p1.adj.lim.pdFVSVU.s)*mu.adj.lim.pdFVSVU.s)

adj.lim.pdFVSVU.testMSE.S.0<-mean((SWRAVG_field_test$adj.lim.pdFVSVU-yest.adj.lim.pdFVSVU.s.gamlss)^2) 
adj.lim.pdFVSVU.testMSE.S<-c(adj.lim.pdFVSVU.testMSE.S,adj.lim.pdFVSVU.testMSE.S.0)
adj.lim.pdFVSVU.AIC.S.0<-AIC(adj.lim.pdFVSVU.simple)
adj.lim.pdFVSVU.AIC.S<-c(adj.lim.pdFVSVU.AIC.S,adj.lim.pdFVSVU.AIC.S.0)


#first categorize the reserve pdPDFVSVU data 
SWRAVG_field_test$adj.lim.pdFVSVU.cat=cut(SWRAVG_field_test$adj.lim.pdFVSVU,
                         breaks=c(-Inf,0.0999,0.24999,0.4999,0.74999,0.8999, Inf),
                labels=c("0-<10%","10-<25%","25-<50%","50-<75%","75-<90%","90-100%"))

#then categorize the predicted data  
yest.adj.lim.pdFVSVU.s.cat=cut(yest.adj.lim.pdFVSVU.s.gamlss,
                           breaks=c(-Inf,0.0999,0.24999,0.4999,0.74999,0.8999, Inf),
                labels=c("0-<10%","10-<25%","25-<50%","50-<75%","75-<90%","90-100%"))

#Create Confusion Matrix
adj.lim.pdFVSVU.S.conf<-confusionMatrix(yest.adj.lim.pdFVSVU.s.cat, SWRAVG_field_test$adj.lim.pdFVSVU.cat,  dnn = c("Prediction", "Reference"))
print(adj.lim.pdFVSVU.S.conf)

#access accuracy and Kappa
adj.lim.pdFVSVU.conf.S.ac<-adj.lim.pdFVSVU.S.conf$overall["Accuracy"]
adj.lim.pdFVSVU.conf.S.K<-adj.lim.pdFVSVU.S.conf$overall["Kappa"]

#add accuracy and Kappa to lists
adj.lim.pdFVSVU.S.Ac<-c(adj.lim.pdFVSVU.S.Ac,adj.lim.pdFVSVU.conf.S.ac)
adj.lim.pdFVSVU.S.K<-c(adj.lim.pdFVSVU.S.K,adj.lim.pdFVSVU.conf.S.K)
}

#average the results across folds
mean(adj.lim.pdFVSVU.S.Ac)
sd(adj.lim.pdFVSVU.S.Ac)/sqrt(length(adj.lim.pdFVSVU.S.Ac))
mean(adj.lim.pdFVSVU.S.K)
sd(adj.lim.pdFVSVU.S.K)/sqrt(length(adj.lim.pdFVSVU.S.K))
mean(adj.lim.pdFVSVU.testMSE.S)
mean(adj.lim.pdFVSVU.AIC.S)



```


### SW RAVG stepGAICAll.A pdTreeCCloss

This code chunk uses the stepGAICAll.A() function to test for linear, smoothed, and interaction terms for each mu, sigma, nu, and tau

4/27 - commenting this section out as results are fairly stable and to reduce run time & output

```{r SW RAVG stepGAICAll.A pdTreeCCloss}

#create initial model for stepGAICAll.A

#pdTreeCCloss.0<-gamlss(pdTreeCCloss ~ L_EA_rdnbr_with, family= BEINF, data=na.omit(SWRAVG_PI))
#pdTreeCCloss.0

#search for best terms to include for each distribution parameter

#model below is commented out, it did not converge
#pdTreeCCloss.1<- stepGAICAll.A(pdTreeCCloss.0, scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f + (L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f)^2 + cs(L_EA_rdnbr_with) + cs(elev) + cs(TCI) + cs(slope) + cs(LEA_preN_f)))

#model below is commented out, it did not converge
#pdTreeCCloss.2<- stepGAICAll.A(pdTreeCCloss.0, scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f + (L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f)^2 + cs(L_EA_rdnbr_with) + cs(elev) + cs(TCI) + cs(slope) + cs(LEA_preN_f)), sigma.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f))

#it did not converge
#pdTreeCCloss.3<- stepGAICAll.A(pdTreeCCloss.0, scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f + (L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f)^2 + cs(L_EA_rdnbr_with) + cs(elev) + cs(TCI) + cs(slope) + cs(LEA_preN_f)), sigma.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f), nu.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f))

#pdTreeCCloss.4<- stepGAICAll.A(pdTreeCCloss.0, scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f + (L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f)^2 + cs(L_EA_rdnbr_with) + cs(elev) + cs(TCI) + cs(slope) + cs(LEA_preN_f)), sigma.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f), nu.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f),tau.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f))


```


### Create fitted values, accuracies and Kappa for pdTreeCCloss

Create predicted values of the response variable for the reserve dataset in order to calcualte confusion matrices, accuracies and kappa. 

Gamlss phrases nu and tau as odds.  The code below converts these odds of nu or tau into probabilities of 0 or 1, respectively. The predicted values are computed using the continuous response (mu) as well as the probability of zero or one.   

```{r SW RAVG pdTreeCCloss gamlss accuracies}

#set up blank lists to store results
pdTreeCCloss.M.Ac<-c()
pdTreeCCloss.M.K<-c()
pdTreeCCloss.testMSE<-c()
pdTreeCCloss.AIC<-c()

#create a blank vector to hold ifelse predictions, aka, predictions with asymptotes
pdTreeCCloss.pred.M.if<-999

for(i in 1:7){

  #Segement your data by fold using the which() function 
    testIndexes <- which(folds_PI==i,arr.ind=TRUE)
    SWRAVG_PI_test <- SWRAVG_PI[testIndexes, ]
    SWRAVG_PI_train <- SWRAVG_PI[-testIndexes, ]

#rephrase results from stepGAICAll.A into the 'pdTreeCCloss.multivar' model below
pdTreeCCloss.multivar<-gamlss(formula=pdTreeCCloss~L_EA_rdnbr_with + cs(slope),  
    sigma.formula = ~L_EA_rdnbr_with, nu.formula = ~1,  
    tau.formula = ~L_EA_rdnbr_with + slope
,family=BEINF,data=na.omit(SWRAVG_PI_train))

# extract new predictions for BEINF gamlss parameters for multivariate model
  pdTreeCCloss.multivar.predAll <- predictAll(pdTreeCCloss.multivar, newdata=SWRAVG_PI_test, type="response") 
  mu.pdTreeCCloss.m <- pdTreeCCloss.multivar.predAll$mu
  nu.pdTreeCCloss.m <- pdTreeCCloss.multivar.predAll$nu
  tau.pdTreeCCloss.m <- pdTreeCCloss.multivar.predAll$tau
  p0.pdTreeCCloss.m <- nu.pdTreeCCloss.m / (1+nu.pdTreeCCloss.m+tau.pdTreeCCloss.m) # probability of zeros
  p1.pdTreeCCloss.m <- tau.pdTreeCCloss.m / (1+nu.pdTreeCCloss.m+tau.pdTreeCCloss.m) # probability of ones

# calculate expected value for new predictions for multivariate model
yest.pdTreeCCloss.m.gamlss <- (1-p0.pdTreeCCloss.m)*(p1.pdTreeCCloss.m+(1-p1.pdTreeCCloss.m)*mu.pdTreeCCloss.m)

pdTreeCCloss.testMSE.0<-mean((SWRAVG_PI_test$pdTreeCCloss-yest.pdTreeCCloss.m.gamlss)^2) 
pdTreeCCloss.testMSE<-c(pdTreeCCloss.testMSE,pdTreeCCloss.testMSE.0)
pdTreeCCloss.AIC.0<-AIC(pdTreeCCloss.multivar)
pdTreeCCloss.AIC<-c(pdTreeCCloss.AIC,pdTreeCCloss.AIC.0)

#first categorize the reserve pdBA data 
SWRAVG_PI_test$pdTreeCCloss.cat=cut(SWRAVG_PI_test$pdTreeCCloss,
                       breaks=c(-Inf,0.0999,0.24999,0.4999,0.74999,0.8999, Inf),
                labels=c("0-<10%","10-<25%","25-<50%","50-<75%","75-<90%","90-100%"))

#then categorize the predicted data  
yest.pdTreeCCloss.m.cat=cut(yest.pdTreeCCloss.m.gamlss,
                      breaks=c(-Inf,0.0999,0.24999,0.4999,0.74999,0.8999, Inf),
                labels=c("0-<10%","10-<25%","25-<50%","50-<75%","75-<90%","90-100%"))

#Create Confusion Matrix
pdTreeCCloss.M.conf<-confusionMatrix(yest.pdTreeCCloss.m.cat, SWRAVG_PI_test$pdTreeCCloss.cat,  dnn = c("Prediction", "Reference"))
print(pdTreeCCloss.M.conf)

#access accuracy and Kappa
pdTreeCCloss.conf.M.ac<-pdTreeCCloss.M.conf$overall["Accuracy"]
pdTreeCCloss.conf.M.K<-pdTreeCCloss.M.conf$overall["Kappa"]

#add accuracy and Kappa to lists
pdTreeCCloss.M.Ac<-c(pdTreeCCloss.M.Ac,pdTreeCCloss.conf.M.ac)
pdTreeCCloss.M.K<-c(pdTreeCCloss.M.K,pdTreeCCloss.conf.M.K)
}

#average the results across folds
mean(pdTreeCCloss.M.Ac)
sd(pdTreeCCloss.M.Ac)/sqrt(length(pdTreeCCloss.M.Ac))
mean(pdTreeCCloss.M.K)
sd(pdTreeCCloss.M.K)/sqrt(length(pdTreeCCloss.M.K))
mean(pdTreeCCloss.testMSE)
mean(pdTreeCCloss.AIC)




#also run the simplest model for comparison

#set up blank lists to store results
pdTreeCCloss.S.Ac<-c()
pdTreeCCloss.S.K<-c()
pdTreeCCloss.testMSE.S<-c()
pdTreeCCloss.AIC.S<-c()

#create a blank vector to hold ifelse predictions, aka, predictions with asymptotes
pdTreeCCloss.pred.S.if<-999

for(i in 1:7){

  #Segement your data by fold using the which() function 
    testIndexes <- which(folds_PI==i,arr.ind=TRUE)
    SWRAVG_PI_test <- SWRAVG_PI[testIndexes, ]
    SWRAVG_PI_train <- SWRAVG_PI[-testIndexes, ]

pdTreeCCloss.simple<-gamlss(formula=pdTreeCCloss~L_EA_rdnbr_with, sigma.formula=~L_EA_rdnbr_with,nu.formula=~L_EA_rdnbr_with, tau.formula=~L_EA_rdnbr_with,family=BEINF,data=na.omit(SWRAVG_PI_train))

# extract new predictions for BEINF gamlss parameters for simple model
pdTreeCCloss.simple.predAll <- predictAll(pdTreeCCloss.simple, newdata=SWRAVG_PI_test, type="response") 
  mu.pdTreeCCloss.s <- pdTreeCCloss.simple.predAll$mu
  nu.pdTreeCCloss.s <- pdTreeCCloss.simple.predAll$nu
  tau.pdTreeCCloss.s <- pdTreeCCloss.simple.predAll$tau
  p0.pdTreeCCloss.s <- nu.pdTreeCCloss.s / (1+nu.pdTreeCCloss.s+tau.pdTreeCCloss.s) # propdabbility of zeros
  p1.pdTreeCCloss.s <- tau.pdTreeCCloss.s / (1+nu.pdTreeCCloss.s+tau.pdTreeCCloss.s) # probability of ones

# calculate expected value for new predictions for simple model
yest.pdTreeCCloss.s.gamlss <- (1-p0.pdTreeCCloss.s)*(p1.pdTreeCCloss.s+(1-p1.pdTreeCCloss.s)*mu.pdTreeCCloss.s)

pdTreeCCloss.testMSE.S.0<-mean((SWRAVG_PI_test$pdTreeCCloss-yest.pdTreeCCloss.s.gamlss)^2) 
pdTreeCCloss.testMSE.S<-c(pdTreeCCloss.testMSE.S,pdTreeCCloss.testMSE.S.0)
pdTreeCCloss.AIC.S.0<-AIC(pdTreeCCloss.simple)
pdTreeCCloss.AIC.S<-c(pdTreeCCloss.AIC.S,pdTreeCCloss.AIC.S.0)

#first categorize the reserve pdPDTreeCCloss data 
SWRAVG_PI_test$pdTreeCCloss.cat=cut(SWRAVG_PI_test$pdTreeCCloss,
                            breaks=c(-Inf,0.0999,0.24999,0.4999,0.74999,0.8999, Inf),
                labels=c("0-<10%","10-<25%","25-<50%","50-<75%","75-<90%","90-100%"))

#then categorize the predicted data  
yest.pdTreeCCloss.s.cat=cut(yest.pdTreeCCloss.s.gamlss,
                            breaks=c(-Inf,0.0999,0.24999,0.4999,0.74999,0.8999, Inf),
                labels=c("0-<10%","10-<25%","25-<50%","50-<75%","75-<90%","90-100%"))

#Create Confusion Matrix
pdTreeCCloss.S.conf<-confusionMatrix(yest.pdTreeCCloss.s.cat, SWRAVG_PI_test$pdTreeCCloss.cat,  dnn = c("Prediction", "Reference"))
print(pdTreeCCloss.S.conf)

#access accuracy and Kappa
pdTreeCCloss.conf.S.ac<-pdTreeCCloss.S.conf$overall["Accuracy"]
pdTreeCCloss.conf.S.K<-pdTreeCCloss.S.conf$overall["Kappa"]

#add accuracy and Kappa to lists
pdTreeCCloss.S.Ac<-c(pdTreeCCloss.S.Ac,pdTreeCCloss.conf.S.ac)
pdTreeCCloss.S.K<-c(pdTreeCCloss.S.K,pdTreeCCloss.conf.S.K)
}

#average the results across folds
mean(pdTreeCCloss.S.Ac)
sd(pdTreeCCloss.S.Ac)/sqrt(length(pdTreeCCloss.S.Ac))
mean(pdTreeCCloss.S.K)
sd(pdTreeCCloss.S.K)/sqrt(length(pdTreeCCloss.S.K))
mean(pdTreeCCloss.testMSE.S)
mean(pdTreeCCloss.AIC.S)

```


### SW RAVG stepGAICAll.A pdCC

This code chunk uses the stepGAICAll.A() function to test for linear, smoothed, and interaction terms for each mu, sigma, nu, and tau

4/27 - commenting this section out as results are fairly stable and to reduce run time & output

```{r SW RAVG stepGAICAll.A pdCC}

#create initial model for stepGAICAll.A

#pdCC.0<-gamlss(pdCC ~ L_EA_rdnbr_with, family= BEINF, data=na.omit(SWRAVG))
#pdCC.0

#search for best terms to include for each distribution parameter

#model below is commented out, it failed to fit sigma
#pdCC.1<- stepGAICAll.A(pdCC.0, scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f + (L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f)^2 + cs(L_EA_rdnbr_with) + cs(elev) + cs(TCI) + cs(slope) + cs(LEA_preN_f)))

#model below is commented out, it failed trying to fit sigma but fits same model as above
#pdCC.2<- stepGAICAll.A(pdCC.0, scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f + (L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f)^2 + cs(L_EA_rdnbr_with) + cs(elev) + cs(TCI) + cs(slope) + cs(LEA_preN_f)), sigma.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f))

#resulting model did not converge it failed to fit sigma
#pdCC.3<- stepGAICAll.A(pdCC.0, scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f + (L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f)^2 + cs(L_EA_rdnbr_with) + cs(elev) + cs(TCI) + cs(slope) + cs(LEA_preN_f)), sigma.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f), nu.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f))
#pdCC.3

#model below did not converge it failed to fit sigma
#pdCC.4<- stepGAICAll.A(pdCC.0, scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f + (L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f)^2 + cs(L_EA_rdnbr_with) + cs(elev) + cs(TCI) + cs(slope) + cs(LEA_preN_f)), sigma.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f), nu.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f),tau.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f))
#pdCC.4

#removed cubic spline terms from the model 
#pdCC.5<- stepGAICAll.A(pdCC.0, scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f + (L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f)^2), sigma.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f), nu.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f),tau.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f))
#pdCC.5

#still fails to fit sigma
#pdCC.6<- stepGAICAll.A(pdCC.0, scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f), sigma.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f), nu.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f),tau.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f))

#pdCC.7<- stepGAICAll.A(pdCC.0, scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with + elev + TCI + slope + LEA_preN_f + cs(L_EA_rdnbr_with) + cs(elev) + cs(TCI) + cs(slope) + cs(LEA_preN_f)), sigma.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with), nu.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with),tau.scope=list(lower=~L_EA_rdnbr_with, upper=~L_EA_rdnbr_with))

```


### Create fitted values, accuracies and Kappa for pdCC

Create predicted values of the response variable for the reserve dataset in order to calcualte confusion matrices, accuracies and kappa. 

Gamlss phrases nu and tau as odds.  The code below converts these odds of nu or tau into probabilities of 0 or 1, respectively. The predicted values are computed using the continuous response (mu) as well as the probability of zero or one.   

```{r SW RAVG pdCC gamlss accuracies}

#set up blank lists to store results
pdCC.M.Ac<-c()
pdCC.M.K<-c()
pdCC.testMSE<-c()
pdCC.AIC<-c()

#create a blank vector to hold ifelse predictions, aka, predictions with asymptotes
pdCC.pred.M.if<-999

for(i in 1:7){

  #Segement your data by fold using the which() function 
    testIndexes <- which(folds_f==i,arr.ind=TRUE)
    SWRAVG_test <- SWRAVG[testIndexes, ]
    SWRAVG_train <- SWRAVG[-testIndexes, ]

#rephrase results from stepGAICAll.A into the 'pdCC.multivar' model below
pdCC.multivar<-gamlss(formula=pdCC~L_EA_rdnbr_with + cs(elev) +  
    cs(TCI),family=BEINF,data=na.omit(SWRAVG_train))

# extract new predictions for BEINF gamlss parameters for multivariate model
  pdCC.multivar.predAll <- predictAll(pdCC.multivar, newdata=SWRAVG_test, type="response") 
  mu.pdCC.m <- pdCC.multivar.predAll$mu
  nu.pdCC.m <- pdCC.multivar.predAll$nu
  tau.pdCC.m <- pdCC.multivar.predAll$tau
  p0.pdCC.m <- nu.pdCC.m / (1+nu.pdCC.m+tau.pdCC.m) # probability of zeros
  p1.pdCC.m <- tau.pdCC.m / (1+nu.pdCC.m+tau.pdCC.m) # probability of ones

# calculate expected value for new predictions for multivariate model
yest.pdCC.m.gamlss <- (1-p0.pdCC.m)*(p1.pdCC.m+(1-p1.pdCC.m)*mu.pdCC.m)

pdCC.testMSE.0<-mean((SWRAVG_test$pdCC-yest.pdCC.m.gamlss)^2) 
pdCC.testMSE<-c(pdCC.testMSE,pdCC.testMSE.0)
pdCC.AIC.0<-AIC(pdCC.multivar)
pdCC.AIC<-c(pdCC.AIC,pdCC.AIC.0)

#first categorize the reserve pdBA data 
SWRAVG_test$pdCC.cat=cut(SWRAVG_test$pdCC,
                            breaks=c(-Inf,0.0999,0.24999,0.4999,0.74999,0.8999, Inf),
                labels=c("0-<10%","10-<25%","25-<50%","50-<75%","75-<90%","90-100%"))

#then categorize the predicted data  
yest.pdCC.m.cat=cut(yest.pdCC.m.gamlss,
                              breaks=c(-Inf,0.0999,0.24999,0.4999,0.74999,0.8999, Inf),
                labels=c("0-<10%","10-<25%","25-<50%","50-<75%","75-<90%","90-100%"))

#Create Confusion Matrix
pdCC.M.conf<-confusionMatrix(yest.pdCC.m.cat, SWRAVG_test$pdCC.cat,  dnn = c("Prediction", "Reference"))
print(pdCC.M.conf)

#access accuracy and Kappa
pdCC.conf.M.ac<-pdCC.M.conf$overall["Accuracy"]
pdCC.conf.M.K<-pdCC.M.conf$overall["Kappa"]

#add accuracy and Kappa to lists
pdCC.M.Ac<-c(pdCC.M.Ac,pdCC.conf.M.ac)
pdCC.M.K<-c(pdCC.M.K,pdCC.conf.M.K)
}

#average the results across folds
mean(pdCC.M.Ac)
sd(pdCC.M.Ac)/sqrt(length(pdCC.M.Ac))
mean(pdCC.M.K)
sd(pdCC.M.K)/sqrt(length(pdCC.M.K))
mean(pdCC.testMSE)
mean(pdCC.AIC)



#also run the simplest model for comparison

#set up blank lists to store results
pdCC.S.Ac<-c()
pdCC.S.K<-c()
pdCC.testMSE.S<-c()
pdCC.AIC.S<-c()

#create a blank vector to hold ifelse predictions, aka, predictions with asymptotes
pdCC.pred.S.if<-999

for(i in 1:7){

  #Segement your data by fold using the which() function 
    testIndexes <- which(folds_f==i,arr.ind=TRUE)
    SWRAVG_test <- SWRAVG[testIndexes, ]
    SWRAVG_train <- SWRAVG[-testIndexes, ]

pdCC.simple<-gamlss(formula=pdCC~L_EA_rdnbr_with, sigma.formula=~L_EA_rdnbr_with,nu.formula=~L_EA_rdnbr_with, tau.formula=~L_EA_rdnbr_with,family=BEINF,data=na.omit(SWRAVG_train))

# extract new predictions for BEINF gamlss parameters for simple model
pdCC.simple.predAll <- predictAll(pdCC.simple, newdata=SWRAVG_test, type="response") 
  mu.pdCC.s <- pdCC.simple.predAll$mu
  nu.pdCC.s <- pdCC.simple.predAll$nu
  tau.pdCC.s <- pdCC.simple.predAll$tau
  p0.pdCC.s <- nu.pdCC.s / (1+nu.pdCC.s+tau.pdCC.s) # propdabbility of zeros
  p1.pdCC.s <- tau.pdCC.s / (1+nu.pdCC.s+tau.pdCC.s) # probability of ones

# calculate expected value for new predictions for simple model
yest.pdCC.s.gamlss <- (1-p0.pdCC.s)*(p1.pdCC.s+(1-p1.pdCC.s)*mu.pdCC.s)

pdCC.testMSE.S.0<-mean((SWRAVG_test$pdCC-yest.pdCC.s.gamlss)^2) 
pdCC.testMSE.S<-c(pdCC.testMSE.S,pdCC.testMSE.S.0)
pdCC.AIC.S.0<-AIC(pdCC.simple)
pdCC.AIC.S<-c(pdCC.AIC.S,pdCC.AIC.S.0)


#first categorize the reserve pdPDCC data 
SWRAVG_test$pdCC.cat=cut(SWRAVG_test$pdCC,
                             breaks=c(-Inf,0.0999,0.24999,0.4999,0.74999,0.8999, Inf),
                labels=c("0-<10%","10-<25%","25-<50%","50-<75%","75-<90%","90-100%"))

#then categorize the predicted data  
yest.pdCC.s.cat=cut(yest.pdCC.s.gamlss,
                             breaks=c(-Inf,0.0999,0.24999,0.4999,0.74999,0.8999, Inf),
                labels=c("0-<10%","10-<25%","25-<50%","50-<75%","75-<90%","90-100%"))

#Create Confusion Matrix
pdCC.S.conf<-confusionMatrix(yest.pdCC.s.cat, SWRAVG_test$pdCC.cat,  dnn = c("Prediction", "Reference"))
print(pdCC.S.conf)

#access accuracy and Kappa
pdCC.conf.S.ac<-pdCC.S.conf$overall["Accuracy"]
pdCC.conf.S.K<-pdCC.S.conf$overall["Kappa"]

#add accuracy and Kappa to lists
pdCC.S.Ac<-c(pdCC.S.Ac,pdCC.conf.S.ac)
pdCC.S.K<-c(pdCC.S.K,pdCC.conf.S.K)
}

#average the results across folds
mean(pdCC.S.Ac)
sd(pdCC.S.Ac)/sqrt(length(pdCC.S.Ac))
mean(pdCC.S.K)
sd(pdCC.S.K)/sqrt(length(pdCC.S.K))
mean(pdCC.testMSE.S)
mean(pdCC.AIC.S)

```
